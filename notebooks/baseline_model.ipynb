{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORvBQcJ8k6vo"
   },
   "source": [
    "# Baseline model classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to make predictions for all six categories on the given dataset using some set of rules.\n",
    "<br>Let's assume that human labellers have labelled these comments based on the certain kind of words present in the comments. So it is worth exploring the comments to check the kind of words used under every category and how many times that word occurred in that category. So in this notebook, six datasets are created from the main dataset, to make the analysis easy for each category. After this, counting and storing the most frequently used words under each category is done. For each category, then we are checking the presence of `top n` words from the frequently used word dictionary, in the comments, to make the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries and load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For preparation lets import the required libraries and the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dir_path = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "8AP6pmPjk6v1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "import operator\n",
    "import pickle\n",
    "import sys  \n",
    "sys.path.append(os.path.join(dir_path, \"src\"))\n",
    "from clean_comments import clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(dir_path, 'data', 'raw', 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "_LbpeVG1k6v3"
   },
   "outputs": [],
   "source": [
    "## Load dataset\n",
    "df = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <br>2. Datasets for each category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset with toxic comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract dataset with toxic label\n",
    "df_toxic = df[df['toxic'] == 1]\n",
    "#Reseting the index\n",
    "df_toxic.set_index(['id'], inplace = True)\n",
    "df_toxic.reset_index(level =['id'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset of severe toxic comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract dataset with Severe toxic label\n",
    "df_severe_toxic = df[df['severe_toxic'] == 1]\n",
    "#Reseting the index\n",
    "df_severe_toxic.set_index(['id'], inplace = True)\n",
    "df_severe_toxic.reset_index(level =['id'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset with obscene comment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "DozMymTMk6v4"
   },
   "outputs": [],
   "source": [
    "#extract dataset with obscens label\n",
    "df_obscene = df[df['obscene'] == 1]\n",
    "#Reseting the index\n",
    "df_obscene.set_index(['id'], inplace = True)\n",
    "df_obscene.reset_index(level =['id'], inplace = True)\n",
    "#df_obscene =df_obscene.drop('comment_text', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset with comments labeled as \"identity_hate\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_identity_hate = df[df['identity_hate'] == 1]\n",
    "#Reseting the index\n",
    "df_identity_hate.set_index(['id'], inplace = True)\n",
    "df_identity_hate.reset_index(level =['id'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset with all the threat comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threat = df[df['threat'] == 1]\n",
    "#Reseting the index\n",
    "df_threat.set_index(['id'], inplace = True)\n",
    "df_threat.reset_index(level =['id'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset of comments with \"Insult\" label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insult = df[df['insult'] == 1]\n",
    "#Reseting the index\n",
    "df_insult.set_index(['id'], inplace = True)\n",
    "df_insult.reset_index(level =['id'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUbpKvRXk6wR"
   },
   "source": [
    "Dataset with comments which have all six labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Ri59MDQck6wS"
   },
   "outputs": [],
   "source": [
    "df_6 = df[(df['toxic']==1) & (df['severe_toxic']==1) &\n",
    "          (df['obscene']==1) & (df['threat']==1)& \n",
    "          (df['insult']==1)& (df['identity_hate']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "1niPINFJk6wS"
   },
   "outputs": [],
   "source": [
    "df_6.set_index(['id'], inplace = True)\n",
    "df_6.reset_index(level =['id'], inplace = True) \n",
    "# df6 = df_6.drop('comment_text', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <br> 3. Preperation of vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "8l4sD-muk6wG"
   },
   "outputs": [],
   "source": [
    "### frequent_words function take dataset as an input and returns two arguments - \n",
    "### all_words and counts.\n",
    "### all_words gives all the words occuring in the provided dataset\n",
    "### counts gives dictionary with keys as a words those exists in the entire dataset and values\n",
    "### as a count of existance of these words in the dataset.\n",
    "\n",
    "def frequent_words(data):\n",
    "    all_word = []\n",
    "    counts = dict()\n",
    "    for i in range (0,len(data)):\n",
    "\n",
    "        ### Load input\n",
    "        input_str = data.comment_text[i]\n",
    "\n",
    "        ### Clean input data\n",
    "        processed_text = clean(input_str)\n",
    "\n",
    "        ### perform tokenization\n",
    "        tokened_text = word_tokenize(processed_text)\n",
    "\n",
    "        ### remove stop words\n",
    "        comment_word = []\n",
    "        for word in tokened_text:\n",
    "            if word not in stopwords.words('english'):\n",
    "                comment_word.append(word)\n",
    "        #print(len(comment_word))\n",
    "        all_word.extend(comment_word)\n",
    "      \n",
    "    for word in all_word:\n",
    "      if word in counts:\n",
    "          counts[word] += 1\n",
    "      else:\n",
    "          counts[word] = 1\n",
    "    \n",
    "    return all_word, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## descend_order_dict funtion takes dataframe as an input and outputs sorted vocab dictionary\n",
    "## with the values sorted in descending order (keys are words and values are word count)\n",
    "\n",
    "def descend_order_dict(data):\n",
    "    all_words, word_count = frequent_words(data)\n",
    "    sorted_dict = dict( sorted(word_count.items(), key=operator.itemgetter(1),reverse=True))\n",
    "    return sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_sequence = df.columns.drop(\"id\")\n",
    "label_sequence = label_sequence.drop(\"comment_text\").tolist()\n",
    "label_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <br>Getting the vocab used in each category in descending order its count "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **`toxic`** category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descend_order_toxic_dict = descend_order_dict(df_toxic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the words most frequently used in toxic comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>For **`severe_toxic`** category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descend_order_severe_toxic_dict =descend_order_dict(df_severe_toxic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the words most frequently used in severe toxic comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>For **`obscene`** category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MhAqDiuA3Tdq",
    "outputId": "571ee676-a48a-41ea-9be5-95015da93467"
   },
   "outputs": [],
   "source": [
    "descend_order_obscene_dict = descend_order_dict(df_obscene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHn2oJaok6wR"
   },
   "source": [
    "These are the words most frequently used in obscene comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>For **`threat`** category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descend_order_threat_dict = descend_order_dict(df_threat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the words most frequently used in severe threat comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>For **`insult`** category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descend_order_insult_dict = descend_order_dict(df_insult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the words most frequently used in comments labeled as an insult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>For **`identity_hate`** category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descend_order_id_hate_dict = descend_order_dict(df_identity_hate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the most frequently used words in the comments labeled as identity_hate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> For comments when all categories are 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descend_order_all_label_dict = descend_order_dict(df_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the most frequently used words in the comments labeled as identity_hate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <br> Picking up the top n words from the descend vocab dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, top 3 words are considered to make the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(descend_order_all_label_dict.keys())[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combining descend vocab dictionaries of all the categories in one dictionary \n",
    "## with categories as their keys\n",
    "\n",
    "all_label_descend_vocab = {'toxic':descend_order_toxic_dict,\n",
    "                       'severe_toxic':descend_order_severe_toxic_dict,\n",
    "                       'obscene':descend_order_obscene_dict,\n",
    "                       'threat':descend_order_threat_dict,\n",
    "                       'insult':descend_order_insult_dict,\n",
    "                       'id_hate':descend_order_id_hate_dict\n",
    "                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this function takes two arguments - all_label_freq_word and top n picks\n",
    "## and outputs a dictionary with categories as keys and list of top 3 words as their values.\n",
    "\n",
    "def dict_top_n_words(all_label_descend_vocab, n):\n",
    "  count = dict()\n",
    "  for label, words in all_label_descend_vocab.items():\n",
    "      word_list = []\n",
    "      for i in range (0,n):\n",
    "        word_list.append(list(words.keys())[i])\n",
    "      count[label] = word_list\n",
    "  return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_label_descend_vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-b4f204d8a2ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### top 3 words from all the vocabs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdict_top_n_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_label_descend_vocab\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'all_label_descend_vocab' is not defined"
     ]
    }
   ],
   "source": [
    "### top 3 words from all the vocabs\n",
    "dict_top_n_words(all_label_descend_vocab,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <br>4. Performance check of baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if the any word from the top 3 words from the six categories exist in the comments\n",
    "def word_intersection(input_str, n,  all_words =all_label_descend_vocab):\n",
    "    toxic_pred = []\n",
    "    severe_toxic_pred = []\n",
    "    obscene_pred = []\n",
    "    threat_pred = []\n",
    "    insult_pred = []\n",
    "    id_hate_pred = []\n",
    "    rule_based_pred = [toxic_pred, severe_toxic_pred, obscene_pred, threat_pred, \n",
    "                   insult_pred,id_hate_pred ]\n",
    "    # top_n_words = dict_top_n_words[all_label_freq_word,n]\n",
    "    \n",
    "    for count,ele in enumerate(list(dict_top_n_words(all_label_descend_vocab,3).values())):\n",
    "\n",
    "        for word in ele:\n",
    "            if (word in input_str):\n",
    "                rule_based_pred[count].append(word)\n",
    "    #print(rule_based_pred)\n",
    "    for i in range (0,len(rule_based_pred)):\n",
    "        if len(rule_based_pred[i])== 0:\n",
    "                rule_based_pred[i]= 0\n",
    "        else:\n",
    "                rule_based_pred[i]= 1\n",
    "    return rule_based_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test\n",
    "word_intersection(df['comment_text'][55], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Uncomment the below cell to get the prediction on the dataset but it is already saved in `rule_base_pred.pkl` in list form to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## store the values of predictions by running the word_intersection function on \n",
    "## all the comments\n",
    "\n",
    "# rule_base_pred = df['comment_text'].apply(lambda x: word_intersection(x,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running above cell, we get the predictions on the entire dataset for each category in `rule_base_pred`, the orginal type of `rule_base_pred` is pandas.core.series.Series. This pandas series is converted into list and saved for future use. This `.pkl` fine can be loaded by running below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save rule_base_pred\n",
    "# file_name = \"rule_base_pred.pkl\"\n",
    "\n",
    "# open_file = open(file_name, \"wb\")\n",
    "# pickle.dump(rule_base_pred, open_file)\n",
    "# # open_file.close()\n",
    "# open_file = open(\"rule_base_pred.pkl\", \"rb\")\n",
    "# pred_rule = pickle.load(open_file)\n",
    "# open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Open the saved rule_base_pred.pkl\n",
    "pkl_file = os.path.join(dir_path, 'model', 'rule_base_pred.pkl')\n",
    "open_file = open(pkl_file, \"rb\")\n",
    "pred_rule = pickle.load(open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## true prediction \n",
    "y_true = df.drop(['id', 'comment_text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, pandas.core.series.Series)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check the type \n",
    "type(y_true), type(pred_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Uncomment pred_rule line in below cell to convert the type of predictions from panda series to list,if not using saved `rule_base_pred.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change the type to list\n",
    "pred_true = y_true.values.tolist()\n",
    "# pred_rule = rule_base_pred.values.tolist()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute accuracy of Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of rule based classifier : 76.5615306039318\n"
     ]
    }
   ],
   "source": [
    "## Accuracy check for decent and not-decent comments classification\n",
    "count = 0\n",
    "for i in range(0, len(df)):\n",
    "    if pred_true[i] == pred_rule[i]:\n",
    "        count = count+1\n",
    "print(\"Overall accuracy of rule based classifier : {}\".format((count/len(df))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the rule implimented here, baseline classifier is classifying decent and not-decent comments with the **accuracy of 76.6%**.Now we have to see if AI based models giver better performance than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of rule based classifier in predicting toxic comments : 89.4554774990443\n",
      "Accuracy of rule based classifier in predicting severe_toxic comments : 88.22906417832814\n",
      "Accuracy of rule based classifier in predicting obscene comments : 96.3282802012897\n",
      "Accuracy of rule based classifier in predicting threat comments : 87.83801567954077\n",
      "Accuracy of rule based classifier in predicting insult comments : 95.77930827029975\n",
      "Accuracy of rule based classifier in predicting identity_hate comments : 98.28916281780525\n",
      "Mean accuracy : 92.65321810771799\n"
     ]
    }
   ],
   "source": [
    "## Category wise accuracy check\n",
    "mean = []\n",
    "for j in range(0, len(pred_true[0])):\n",
    "    count = 0\n",
    "    for i in range(0, len(df)):\n",
    "        if pred_true[i][j] == pred_rule[i][j]:\n",
    "            count = count+1\n",
    "    mean.append(count/len(df)*100)\n",
    "    print(\"Accuracy of rule based classifier in predicting {} comments : {}\".format(label_sequence[j],(count/len(df))*100))\n",
    "print(\"Mean accuracy : {}\".format(np.array(mean).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean accuracy of our *rule-based-model* is 92.7%<br>\n",
    "Minimum accuracy for predicting `toxic `, `severe_toxic `, `obscene `, `threat `, `insult `, or  `identity_hate ` class of the Baseline model is more that 88%.\n",
    "<br>Accuracies for:\n",
    "<ol>\n",
    "<li>`toxic `: 89.4%</li>\n",
    "<li>`severe_toxic `: 88.2%</li>\n",
    "<li>`obscene `: 96.3%</li>\n",
    "<li>`threat `: 87.8%</li>\n",
    "<li>`insult `: 95.8%</li>\n",
    "<li>`identity_hate `: 98.3%</li>\n",
    "</ol>\n",
    "<br>In my opinion this model is doing quite good. As we know the dataset have more samples for toxic comments as compared to rest of the categories but this model still managed to predict with 89.4% of accuracy by just considering the top 3 words from its very large vocabulary. It may perform better if we consider more than 3 words from its vocab, because top 3 words not necessarily a true representaion of this category.\n",
    "<br>On the other hand, `obscene `, `insult `, and  `identity_hate ` have very good accuracy rates, seems like human labellers looked for these top 3 words to label comments under these categories.\n",
    "<br>For `threat ` category, the model should perform well as the number of sample for this category is just 478, that means it has smaller vocab comparative to other classes. but seems like human labellers looked at more than these top 3 words of its vocab. It could be checked by tweaking the number of top n words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp=np.array([np.array(xi) for xi in pred_rule])\n",
    "type(yp)\n",
    "# type(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 6)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt=np.array([np.array(xi) for xi in pred_true])\n",
    "type(yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 6)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard score is : 0.25033619059083945\n"
     ]
    }
   ],
   "source": [
    "print(\"Jaccard score is : {}\".format(jaccard_score(yt,yp, average= 'weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `rule based model` is really bad seeing jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "etc.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
